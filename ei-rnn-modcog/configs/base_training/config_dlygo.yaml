seed: 1
device: auto
outdir: outputs/dlygo_tuned

tasks: ["dlygo"]

data:
  source: cached
  batch_size: 256
  seq_len: 80      # covers fixation+stimulus+delay+decision comfortably
  cache:
    num_batches: 256
    val_frac: 0.1
    build_if_missing: true
    seed: 7
    paths:
      dlygo: outputs/cache/dlygo_fast.npz  # <-- fix key to match task name

model:
  hidden_size: 256
  exc_frac: 0.8
  spectral_radius: 1.3
  input_scale: 1.0
  leak: 0.9                  # stronger memory than 0.2; less rigid than 1.0
  nonlinearity: softplus
  readout: all
  softplus_beta: 10.0
  softplus_threshold: 20.0

optim:
  algorithm: gd              # start with plain GD for stability
  gd:
    lr: 0.05                 # conservative step size
    momentum: 0.9
    weight_decay: 1e-5
  # (Optional) Once learning plateaus, you can switch to EG by setting:
  # algorithm: eg
  # eg:
  #   lr: 0.05
  #   momentum: 0.0
  #   weight_decay: 1e-5
  #   min_magnitude: 1e-6
  # gd:
  #   lr: 0.02
  #   momentum: 0.9
  #   weight_decay: 1e-5

train:
  num_epochs: 40
  steps_per_epoch: 800
  val_batches: 40
  grad_clip: 0.5
  input_noise_std: 0.0
  fixdown_weight: 0.1
  spectral_renorm_every: 500  # keep max singular value near target
  mask_threshold: 0.5
  task_sampling: round_robin
  task_weights: []
  label_smoothing: 0.0        # crisper targets for delayed decision

  row_sum_zero:
    enabled: true
    weight: 0.05              # much lighter; lets recurrent dynamics form
    per_sign: true
